{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWaiIGsJkuOFbFVD0qDj3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnyjahangir/Documents/blob/main/Milestone3_CyberSecurity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo7_kX3Itx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "\n",
        "# Fix for XGBoost on Mac OS\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    has_xgboost = True\n",
        "except:\n",
        "    print(\"XGBoost not available. Using GradientBoostingClassifier as a replacement.\")\n",
        "    has_xgboost = False\n",
        "\n",
        "# --- 1. Load Primary Dataset (UGRansome) ---\n",
        "primary_df = pd.read_csv('/Users/sunnyjahangir/Downloads/UGRansome_Dataset_2024.csv')\n",
        "print(f\"Primary dataset shape: {primary_df.shape}\")\n",
        "\n",
        "# Remove duplicates\n",
        "initial_rows = len(primary_df)\n",
        "primary_df.drop_duplicates(inplace=True)\n",
        "print(f\"Removed {initial_rows - len(primary_df)} duplicate rows\")\n",
        "\n",
        "# --- 2. Load Windows Malware API Functions Dataset ---\n",
        "# Load only the API functions dataset\n",
        "api_functions = pd.read_csv('/Users/sunnyjahangir/PycharmProjects/MachineLearning/PythonProject4/analysis_results/API_Functions_samples.csv')\n",
        "print(f\"API functions shape: {api_functions.shape}\")\n",
        "\n",
        "# --- 3. Feature Engineering ---\n",
        "print(\"\\n--- Feature Engineering ---\")\n",
        "\n",
        "# Feature Engineering for Primary Dataset\n",
        "# Add network-based features\n",
        "if 'Netflow_Bytes' in primary_df.columns:\n",
        "    # Log transform for skewed numerical data\n",
        "    primary_df['Log_Netflow_Bytes'] = np.log1p(primary_df['Netflow_Bytes'])\n",
        "\n",
        "# Create Protocol-Port combinations if both exist\n",
        "if 'Protocol' in primary_df.columns and 'Port' in primary_df.columns:\n",
        "    primary_df['Protocol_Port'] = primary_df['Protocol'] + '_' + primary_df['Port'].astype(str)\n",
        "\n",
        "# --- API Functions Feature Engineering ---\n",
        "# Count non-null APIs per sample\n",
        "api_counts = api_functions.iloc[:, 2:].notna().sum(axis=1)\n",
        "api_functions['API_Count'] = api_counts\n",
        "\n",
        "# Get most common API functions (top 20)\n",
        "common_apis = []\n",
        "for col in api_functions.columns[2:]:\n",
        "    if col != 'API_Count' and api_functions[col].notna().sum() > api_functions.shape[0] * 0.1:  # At least 10% occurrence\n",
        "        common_apis.append(col)\n",
        "common_apis = common_apis[:20]  # Keep top 20 most common\n",
        "\n",
        "# Create binary features for common APIs\n",
        "for api in common_apis:\n",
        "    if api in api_functions.columns:\n",
        "        api_functions[f'Uses_{api}'] = api_functions[api].notna().astype(int)\n",
        "\n",
        "# --- 4. Prepare Primary Dataset ---\n",
        "print(\"\\n--- Processing Primary Dataset ---\")\n",
        "\n",
        "# Define target for primary dataset\n",
        "primary_target = 'Threats'\n",
        "\n",
        "# Select features from primary dataset\n",
        "primary_features = [\n",
        "    'Time', 'Protocol', 'Flag', 'Clusters', 'Netflow_Bytes', 'Port',\n",
        "    'Log_Netflow_Bytes', 'Protocol_Port'  # Include engineered features\n",
        "]\n",
        "# Filter to include only columns that exist\n",
        "primary_features = [col for col in primary_features if col in primary_df.columns]\n",
        "\n",
        "# Separate features and target\n",
        "X_primary = primary_df[primary_features].copy()\n",
        "y_primary = primary_df[primary_target].copy()\n",
        "\n",
        "# Process categorical and numerical features\n",
        "primary_cat_cols = X_primary.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "primary_num_cols = X_primary.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Handle missing values\n",
        "for col in primary_num_cols:\n",
        "    if X_primary[col].isnull().any():\n",
        "        X_primary[col] = X_primary[col].fillna(X_primary[col].median())\n",
        "\n",
        "for col in primary_cat_cols:\n",
        "    if X_primary[col].isnull().any():\n",
        "        X_primary[col] = X_primary[col].fillna(X_primary[col].mode()[0])\n",
        "\n",
        "# Encode categorical features\n",
        "for col in primary_cat_cols:\n",
        "    if col in X_primary.columns:\n",
        "        le = LabelEncoder()\n",
        "        X_primary[col] = le.fit_transform(X_primary[col])\n",
        "\n",
        "# Encode target variable\n",
        "primary_target_encoder = LabelEncoder()\n",
        "y_primary_encoded = primary_target_encoder.fit_transform(y_primary)\n",
        "print(f\"Primary target classes: {primary_target_encoder.classes_}\")\n",
        "\n",
        "# --- 5. Process API Functions Dataset ---\n",
        "print(\"\\n--- Processing API Functions Dataset ---\")\n",
        "\n",
        "# Define features and target\n",
        "X_api = api_functions.drop(['SHA256', 'Label'], axis=1)\n",
        "y_api = api_functions['Label']\n",
        "\n",
        "# Process categorical and numerical features\n",
        "api_cat_cols = X_api.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "api_num_cols = X_api.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Handle missing values\n",
        "for col in api_num_cols:\n",
        "    if X_api[col].isnull().any():\n",
        "        X_api[col] = X_api[col].fillna(X_api[col].median())\n",
        "\n",
        "for col in api_cat_cols:\n",
        "    if X_api[col].isnull().any():\n",
        "        X_api[col] = X_api[col].fillna(X_api[col].mode()[0])\n",
        "\n",
        "# Encode categorical features\n",
        "for col in api_cat_cols:\n",
        "    if col in X_api.columns:\n",
        "        le = LabelEncoder()\n",
        "        X_api[col] = le.fit_transform(X_api[col])\n",
        "\n",
        "# Encode target variable if needed\n",
        "if y_api.dtype == 'object':\n",
        "    api_target_encoder = LabelEncoder()\n",
        "    y_api_encoded = api_target_encoder.fit_transform(y_api)\n",
        "    print(f\"API target classes: {api_target_encoder.classes_}\")\n",
        "else:\n",
        "    y_api_encoded = y_api.values\n",
        "    print(f\"API target classes: {sorted(y_api.unique())}\")\n",
        "\n",
        "print(f\"API features shape: {X_api.shape}\")\n",
        "\n",
        "# --- 6. Data Splitting ---\n",
        "print(\"\\n--- Data Splitting ---\")\n",
        "\n",
        "# Split primary dataset\n",
        "X_train_primary, X_test_primary, y_train_primary, y_test_primary = train_test_split(\n",
        "    X_primary, y_primary_encoded, test_size=0.2, random_state=42, stratify=y_primary_encoded\n",
        ")\n",
        "\n",
        "# Split API dataset\n",
        "X_train_api, X_test_api, y_train_api, y_test_api = train_test_split(\n",
        "    X_api, y_api_encoded, test_size=0.2, random_state=42, stratify=y_api_encoded\n",
        ")\n",
        "\n",
        "# --- 7. Feature Scaling ---\n",
        "print(\"\\n--- Feature Scaling ---\")\n",
        "\n",
        "# Scale primary features\n",
        "primary_scaler = StandardScaler()\n",
        "X_train_primary_scaled = X_train_primary.copy()\n",
        "X_test_primary_scaled = X_test_primary.copy()\n",
        "X_train_primary_scaled[primary_num_cols] = primary_scaler.fit_transform(X_train_primary[primary_num_cols])\n",
        "X_test_primary_scaled[primary_num_cols] = primary_scaler.transform(X_test_primary[primary_num_cols])\n",
        "\n",
        "# Scale API features\n",
        "api_scaler = StandardScaler()\n",
        "X_train_api_scaled = api_scaler.fit_transform(X_train_api)\n",
        "X_test_api_scaled = api_scaler.transform(X_test_api)\n",
        "\n",
        "# --- 8. Handle Class Imbalance ---\n",
        "print(\"\\n--- Handling Class Imbalance ---\")\n",
        "\n",
        "# Apply SMOTE to primary dataset\n",
        "smote_primary = SMOTE(random_state=42)\n",
        "X_train_primary_smote, y_train_primary_smote = smote_primary.fit_resample(X_train_primary_scaled, y_train_primary)\n",
        "print(f\"Primary training data shape after SMOTE: {X_train_primary_smote.shape}\")\n",
        "print(f\"Primary class distribution after SMOTE: {np.bincount(y_train_primary_smote)}\")\n",
        "\n",
        "# Apply SMOTE to API dataset\n",
        "smote_api = SMOTE(random_state=42)\n",
        "X_train_api_smote, y_train_api_smote = smote_api.fit_resample(X_train_api_scaled, y_train_api)\n",
        "print(f\"API training data shape after SMOTE: {X_train_api_smote.shape}\")\n",
        "print(f\"API class distribution after SMOTE: {np.bincount(y_train_api_smote)}\")\n",
        "\n",
        "# --- 9. Train Models ---\n",
        "print(\"\\n--- Training Models ---\")\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
        "    'SVC': SVC(probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "# Add XGBoost if available, otherwise use Gradient Boosting\n",
        "if has_xgboost:\n",
        "    models['XGBoost'] = xgb.XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        n_jobs=1,  # Use single thread to avoid OpenMP issues\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='mlogloss',\n",
        "        tree_method='hist'  # Use histogram-based algorithm which is faster\n",
        "    )\n",
        "else:\n",
        "    models['Gradient Boosting'] = GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "# Train and evaluate models on primary dataset\n",
        "primary_results = {}\n",
        "primary_models = {}\n",
        "\n",
        "print(\"\\nTraining on Primary Dataset:\")\n",
        "for name, model in models.items():\n",
        "    print(f\"  Training {name}...\")\n",
        "    model.fit(X_train_primary_smote, y_train_primary_smote)\n",
        "\n",
        "    # Save the trained model\n",
        "    primary_models[name] = model\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_primary_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_primary, y_pred)\n",
        "    f1 = f1_score(y_test_primary, y_pred, average='weighted')\n",
        "\n",
        "    # Store results\n",
        "    primary_results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "\n",
        "    print(f\"  {name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Train and evaluate models on API dataset\n",
        "api_results = {}\n",
        "api_models = {}\n",
        "\n",
        "print(\"\\nTraining on API Function Dataset:\")\n",
        "for name, model in models.items():\n",
        "    print(f\"  Training {name}...\")\n",
        "    model.fit(X_train_api_smote, y_train_api_smote)\n",
        "\n",
        "    # Save the trained model\n",
        "    api_models[name] = model\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_api_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_api, y_pred)\n",
        "    f1 = f1_score(y_test_api, y_pred, average='weighted')\n",
        "\n",
        "    # Store results\n",
        "    api_results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "\n",
        "    print(f\"  {name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# --- 10. Model Ranking and Visualization ---\n",
        "print(\"\\n--- Model Ranking and Visualization ---\")\n",
        "\n",
        "# Create DataFrames for results\n",
        "primary_df_results = pd.DataFrame.from_dict(primary_results, orient='index')\n",
        "primary_df_results['Dataset'] = 'UGRansome'\n",
        "\n",
        "api_df_results = pd.DataFrame.from_dict(api_results, orient='index')\n",
        "api_df_results['Dataset'] = 'API Functions'\n",
        "\n",
        "# Combine results\n",
        "all_results = pd.concat([primary_df_results, api_df_results])\n",
        "all_results['Model'] = all_results.index\n",
        "all_results.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Sort by accuracy (descending)\n",
        "ranked_by_accuracy = all_results.sort_values('Accuracy', ascending=False)\n",
        "print(\"\\nModels Ranked by Accuracy:\")\n",
        "print(ranked_by_accuracy[['Model', 'Dataset', 'Accuracy', 'F1 Score']])\n",
        "\n",
        "# Sort by F1 Score (descending)\n",
        "ranked_by_f1 = all_results.sort_values('F1 Score', ascending=False)\n",
        "print(\"\\nModels Ranked by F1 Score:\")\n",
        "print(ranked_by_f1[['Model', 'Dataset', 'Accuracy', 'F1 Score']])\n",
        "\n",
        "# Find the best model overall\n",
        "best_model_idx = ranked_by_f1.index[0]\n",
        "best_model_name = ranked_by_f1.loc[best_model_idx, 'Model']\n",
        "best_model_dataset = ranked_by_f1.loc[best_model_idx, 'Dataset']\n",
        "best_model_accuracy = ranked_by_f1.loc[best_model_idx, 'Accuracy']\n",
        "best_model_f1 = ranked_by_f1.loc[best_model_idx, 'F1 Score']\n",
        "\n",
        "print(f\"\\nBest Overall Model: {best_model_name} on {best_model_dataset} Dataset\")\n",
        "print(f\"  Accuracy: {best_model_accuracy:.4f}\")\n",
        "print(f\"  F1 Score: {best_model_f1:.4f}\")\n",
        "\n",
        "# --- 11. Detailed Evaluation of the Best Model ---\n",
        "print(\"\\n--- Detailed Evaluation of the Best Model ---\")\n",
        "\n",
        "# Get the actual best model\n",
        "if best_model_dataset == 'UGRansome':\n",
        "    best_model = primary_models[best_model_name]\n",
        "    X_test = X_test_primary_scaled\n",
        "    y_test = y_test_primary\n",
        "    target_encoder = primary_target_encoder\n",
        "else:\n",
        "    best_model = api_models[best_model_name]\n",
        "    X_test = X_test_api_scaled\n",
        "    y_test = y_test_api\n",
        "    target_encoder = api_target_encoder\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report for the Best Model:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_encoder.classes_,\n",
        "            yticklabels=target_encoder.classes_)\n",
        "plt.title(f'Confusion Matrix - {best_model_name} on {best_model_dataset}')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('best_model_confusion_matrix.png')\n",
        "plt.close()\n",
        "\n",
        "# --- 12. Visualization of Model Performance ---\n",
        "print(\"\\n--- Creating Performance Visualizations ---\")\n",
        "\n",
        "# Setup for visualizations\n",
        "plt.style.use('ggplot')\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
        "\n",
        "# 1. Bar chart comparison of all models\n",
        "plt.figure(figsize=(14, 8))\n",
        "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])\n",
        "\n",
        "# Accuracy comparison\n",
        "ax1 = plt.subplot(gs[0])\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(models))\n",
        "\n",
        "primary_acc = [primary_results[model]['Accuracy'] for model in models]\n",
        "api_acc = [api_results[model]['Accuracy'] for model in models]\n",
        "\n",
        "ax1.bar(index, primary_acc, bar_width, label='UGRansome', color=colors[0], alpha=0.8)\n",
        "ax1.bar(index + bar_width, api_acc, bar_width, label='API Functions', color=colors[1], alpha=0.8)\n",
        "\n",
        "ax1.set_xlabel('Model')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Accuracy Comparison')\n",
        "ax1.set_xticks(index + bar_width / 2)\n",
        "ax1.set_xticklabels(models.keys())\n",
        "ax1.legend()\n",
        "\n",
        "# F1 Score comparison\n",
        "ax2 = plt.subplot(gs[1])\n",
        "primary_f1 = [primary_results[model]['F1 Score'] for model in models]\n",
        "api_f1 = [api_results[model]['F1 Score'] for model in models]\n",
        "\n",
        "ax2.bar(index, primary_f1, bar_width, label='UGRansome', color=colors[0], alpha=0.8)\n",
        "ax2.bar(index + bar_width, api_f1, bar_width, label='API Functions', color=colors[1], alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel('Model')\n",
        "ax2.set_ylabel('F1 Score')\n",
        "ax2.set_title('F1 Score Comparison')\n",
        "ax2.set_xticks(index + bar_width / 2)\n",
        "ax2.set_xticklabels(models.keys())\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_performance_comparison.png')\n",
        "plt.close()\n",
        "\n"
      ]
    }
  ]
}